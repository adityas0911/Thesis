train:
  clip_observations: 14
  clip_rewards: 40
  gamma: 0.997
  epsilon: 1.0e-8
  policy: 'MultiInputPolicy'
  features_extractor_arguments:
    use_coordinate_channels: true
    add_robot_position_channel: true
    convolution_channels: [32,
                           64]
    global_embedding_dimension: 256
    scalar_embedding_dimension: 64
  network_architecture:
    pi: [256,
         128]
    vf: [256,
         128]
  start_learning_rate: 4.0e-4
  end_learning_rate: 1.0e-4
  number_steps: 2_000
  batch_size: 800
  number_epochs: 8
  generalized_advantage_estimation_lambda: 0.97
  clip_range: 0.2
  normalize_advantage: true
  entropy_coefficient: 0.03
  value_function_coefficient: 0.5
  maximum_gradient_norm: 0.5
  verbose: 1
  stats_window_size: 100
  _init_setup_model: true
  total_timesteps: 1_000_000
  checkpoint_frequency: 100_000
environment:
  seed: 42
  sensor_alpha: 0.3
  environment_size: 20
  vision_range: 2
  maximum_steps: 400
reward:
  step_weight: 1
  distance_reduction_weight: 9
  entropy_reduction_weight: 3
  terminated_weight: 270
visualization:
  frames_per_second: 20
  render_mode: 'human'
  show_heatmap: true
  show_victim: true
  show_path: true
  window_size: 700
  render: true
load_maskableppo:
  normalize_observations: true
  normalize_rewards: false
evaluation:
  training_episode_percentage: 0.2
  random: true
  maskableppo: true
  pomcp: true
random:
  seed: 42
pomcp:
  seed: 42
  number_simulations: 20
  maximum_depth: 20
  exploration_constant: 2.0
  number_particles: 200
