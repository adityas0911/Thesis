train:
  clip_observations: 10
  clip_rewards: 10
  gamma: 0.997
  epsilon: 1.0e-8
  policy: 'MultiInputPolicy'
  features_extractor_arguments:
    cnn_channels: [16,
                   32,
                   64]
    cnn_kernel_sizes: [3,
                       3,
                       3]
    cnn_strides: [1,
                  2,
                  2]
    cnn_embedding_dimensions: 256
    scalar_hidden_sizes: [32]
    scalar_embedding_dimensions: 32
  network_architecture:
    pi: [128,
         64]
    vf: [128,
         64]
  start_learning_rate: 3.0e-4
  end_learning_rate: 1.0e-4
  number_steps: 1024
  batch_size: 512
  number_epochs: 10
  generalized_advantage_estimation_lambda: 0.97
  clip_range: 0.2
  normalize_advantage: true
  entropy_coefficient: 0.01
  value_function_coefficient: 0.7
  maximum_gradient_norm: 0.5
  verbose: 1
  stats_window_size: 100
  _init_setup_model: true
  total_timesteps: 10_000_000
  checkpoint_frequency: 100_000
environment:
  seed: null
  environment_size: 20
  vision_range: 1
  maximum_steps: 400
reward:
  step_weight: 1
  terminated_weight: 1
  truncated_weight: 1
visualization:
  frames_per_second: 20
  render_mode: 'human'
  show_heatmap: true
  show_victim: true
  show_path: true
  window_size: 700
  render: true
load_maskableppo:
  normalize_observations: false
  normalize_rewards: true
evaluation:
  training_episode_percentage: 0.2
  random: true
  maskableppo: true
  pomcp: false
random:
  seed: null
pomcp:
  seed: null
  number_simulations: 20
  maximum_depth: 20
  exploration_constant: 2.0
  number_particles: 200
